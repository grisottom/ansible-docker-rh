---
- hosts: master, slaves

  vars_files:
    - vars/main.yml

  any_errors_fatal: true

  vars: 

    app_dir: "/u01/app"  #/home/{{ jboss_os_user }}"
    jboss_version: "jboss-eap-7.4"    
    app_dir_JBOSS: "{{ app_dir }}/jboss/{{ jboss_version }}"
    config_domain_dir_JBOSS: "{{ app_dir_JBOSS }}/domain/configuration"

    config_scripts_dir: "{{ app_dir }}/scripts"

    JBOSS_PROFILE_FROM: "default"
    JBOSS_PROFILE_TO: "A_profile"
    JBOSS_SERVER_GROUP: "server_group_A"
    JBOSS_SERVER_CONFIG: "A_config"
    
    PATH: "{{ ansible_env.PATH }}"
    JBOSS_HOME: "{{ ansible_env.JBOSS_HOME }}"
    JAVA_HOME: "{{ ansible_env.JAVA_HOME }}"
    HOST_CONFIG: "{{ host_config }}"  #from group_vars
    JBOSS_OPTION: "{{ jboss_option }}" #from group_vars

    # create a variable named "shell_env" that is a dictionary
    shell_env:
      PATH: "{{ PATH }}"
      JBOSS_HOME: "{{ JBOSS_HOME }}"
      JAVA_HOME: "{{ JAVA_HOME }}"

      HOST_CONFIG: "{{ HOST_CONFIG }}"
      JBOSS_OPTION: "{{ JBOSS_OPTION }}"

  # pre_tasks:

  # - name: inspect env vars <<<<<<========================
  #   debug:
  #     var: ansible_facts.env      

  #------
  # - name: print shell_env, 
  #   debug: 
  #     msg: shell_env={{ shell_env }}

  # - name: show all the hosts matching the pattern 'master'
  #   ansible.builtin.debug:
  #     msg: "{{ item }}"
  #   with_inventory_hostnames:
  #     - master

  tasks:

    #--------------------------------------------
    - block:  #pre-config  (copy config files to master and slaves)

      - name: get 'master' hostname from inventory, put in variable 'master_hostname'
        ansible.builtin.set_fact:
          master_hostname: "{{ item }}"
        with_inventory_hostnames:
          - master

      - name: show variable 'master_hostname'
        ansible.builtin.debug:
          msg: "{{ master_hostname }}"

      #------
      - name: template, from 'host-CONFIG-master-j2.xml' to 'host-CONFIG-master.xml' in 'master'
        when: inventory_hostname in groups["master"]
        ansible.builtin.template:
          src: ./template/{{ item.src }}
          dest: "{{ config_domain_dir_JBOSS }}/{{ item.dest }}"
          mode: 0775
        with_items:
          - {src: 'host-CONFIG-master-j2.xml', dest: 'host-CONFIG-master.xml'}

      #------
      - name: template 'host-CONFIG-slave-j2.xml' to 'host-CONFIG-slave.xml' in 'slaves'
        when: inventory_hostname in groups["slaves"]
        ansible.builtin.template:
          src: ./template/{{ item.src }}
          dest: "{{ config_domain_dir_JBOSS }}/{{ item.dest }}"
          mode: 0775
        with_items:
          - {src: 'host-CONFIG-slave-j2.xml', dest: 'host-CONFIG-slave.xml'}

      #------
      - name: Copy/Transfer CONFIG and START scripts to 'master' and 'slaves'
        ansible.builtin.copy: 
          src: ./scripts/       
          dest: "{{ config_scripts_dir }}"
          mode: 0775

      # end of block, same user for all tasks
      become: true
      become_user: "{{ jboss_os_user }}"

      rescue:  #config & start
      - name: Show result with line breaks
        ansible.builtin.debug:
          var: results.stdout_lines

      - name: Abort execution
        when: { ansible_failed_result.failed }
        ansible.builtin.fail:
          msg: "{{ ansible_failed_result }}"

    #---------------------------------------------
    - name: ini config in master - add mgmt_user
      when: inventory_hostname in groups["master"]
      block:
      - name: execute INI CONFIG script in 'master'
        ansible.builtin.shell:
        args:
          chdir: "{{ config_scripts_dir }}/ini-config/"
          cmd: ./jboss-ini-config-master.sh {{ jboss_mgmt_user }} {{ jboss_mgmt_user_pwd }}
        register: results
        no_log: false         # log in next task

      - name: Show sucessful result of previous task with line breaks
        ansible.builtin.debug:
          var: results.stdout_lines

      rescue:  #config master
      - name: Abort execution in case of failure
        when: { ansible_failed_result.failed }
        ansible.builtin.fail:
          msg: "{{ ansible_failed_result }}"

    #---------------------------------------------
    - name: ini config in slaves - add app_user
      when: inventory_hostname in groups["slaves"]
      block:

      - name: execute INI CONFIG script in 'slaves'
        ansible.builtin.shell:
        args:
          chdir: "{{ config_scripts_dir }}/ini-config/"
          cmd: ./jboss-ini-config-slave.sh {{ jboss_app_user }} {{ jboss_app_user_pwd }};
        register: results
        #ignore_errors: true  # in order to continue processing
        no_log: true         # log in rescue block

      - name: Show sucessful result of previous task with line breaks
        ansible.builtin.debug:
          var: results.stdout_lines

      rescue:  #config
      - name: Abort execution in case of failure
        when: { ansible_failed_result.failed }
        ansible.builtin.fail:
          msg: "{{ ansible_failed_result }}"

    #---------------------------------------------
    - name: start master
      when: inventory_hostname in groups["master"]
      block:   

      - name: execute START script in 'master'
        ansible.builtin.shell:
        #when: inventory_hostname in groups["master"] #Already active for block       
        args:
          chdir: "{{ config_scripts_dir }}/start/"
          cmd: nohup ./jboss-start.sh 
        register: results
        no_log: true
        
      - name: Show sucessful result of previous task with line breaks
        ansible.builtin.debug:
          var: results.stdout_lines

      rescue:  #config
      - name: Show error results with line breaks 
        ansible.builtin.debug:
          var: ansible_failed_result.stdout_lines

      - name: Abort execution in case of failure
        when: { ansible_failed_result.failed }
        ansible.builtin.fail:
          msg: "{{ ansible_failed_result.failed }}"

      # end of block, for all tasks
      environment:
        - "{{ shell_env }}"
      become: true
      become_user: "{{ jboss_os_user }}"

    #---------------------------------------------      
    - name: start slaves
      when: inventory_hostname in groups["slaves"]
      block:

      - name: execute START script in 'slaves'
        ansible.builtin.shell:
        args:
          chdir: "{{ config_scripts_dir }}/start/"
          cmd: nohup ./jboss-start.sh 
          #nohup = 'no hung up', Keep shell running after end of task
        register: results
        #ignore_errors: true  
        no_log: true

      - name: Show sucessful result of previous task with line breaks
        when: inventory_hostname in groups["master"]    
        ansible.builtin.debug:
          var: results.stdout_lines

      rescue:  #config
      - name: Abort execution in case of failure
        when: { ansible_failed_result.failed }
        ansible.builtin.fail:
          msg: "{{ ansible_failed_result }}"

      # environment, for block
      environment:
        - "{{ shell_env }}"   #variables PATH, JBOSS_HOME, HOST_CONFIG, JBOSS_OPTION
      become: true
      become_user: "{{ jboss_os_user }}"

    #---------------------------------------------
    - block: #Config jboss to run as service 
             #https://access.redhat.com/documentation/en-us/red_hat_jboss_enterprise_application_platform/7.0/html/installation_guide/configuring_jboss_eap_to_run_as_a_service
             #https://ernayd.medium.com/how-to-install-jboss-eap-7-3-on-centos-8-rhel-8-aaa667905bcc

      #1.Copy the modified service configuration file to the /etc/default directory.
      - name: 1. template, from 'jboss-eap-j2.conf' to 'jboss-eap.conf'
        ansible.builtin.template:
          src: ./template/{{ item.src }}
          dest: "/etc/default/{{ item.dest }}"
          mode: 0775
        with_items:
          - {src: 'jboss-eap-j2.conf', dest: 'jboss-eap.conf'}

      # #2.Copy the service startup script to the /etc/init.d directory, and give it execute permissions:
      # - name: 2. Copy the service startup script
      #   ansible.builtin.command:
      #     cmd: "cp $JBOSS_HOME/bin/init.d/jboss-eap-rhel.sh /etc/init.d"

      # #2.1.chmod +x /etc/init.d/jboss-eap-rhel.sh
      # - name: 2.1 chmod +x /etc/init.d/jboss-eap-rhel.sh
      #   ansible.builtin.command:
      #     cmd: "chmod +x /etc/init.d/jboss-eap-rhel.sh"

      #2.Copy the service startup script to the /etc/init.d directory, and give it execute permissions:
      - name: 2. Copy the service startup script
        ansible.builtin.copy:
          remote_src: true
          src: "{{ JBOSS_HOME }}/bin/init.d/jboss-eap-rhel.sh"
          dest: "/etc/init.d/"
          mode: u=rwx,g=rw,o=r
          #{{ JBOSS_HOME }} /u01/app/jboss/jboss-eap-7.4

      # #3.Add the new jboss-eap-rhel.sh service to list of automatically started services using the chkconfig service management command    
      # - name: 3. chkconfig --add jboss-eap-rhel.sh
      #   ansible.builtin.command:
      #     cmd: chkconfig --add jboss-eap-rhel.sh

      #3.Enable JBoss EAP service to start when the system start.
      - name: 3. chkconfig --add jboss-eap-rhel.sh
        ansible.builtin.command:
          chdir: "{{ JBOSS_HOME }}/bin/init.d/"
          cmd: "systemctl enable jboss-eap-rhel.sh"

      # #4. Test that the service has been installed correctly
      # - name: 4. service jboss-eap-rhel start
      #   ansible.builtin.command:
      #     cmd: service jboss-eap-rhel start

      #  #5. Make the service start automatically when the Red Hat Enterprise Linux server starts,
      # - name: 5. chkconfig jboss-eap-rhel.sh on
      #   ansible.builtin.command:
      #     cmd: chkconfig jboss-eap-rhel.sh on

      # - name: Enable jboss-eap-rhel service start
      #   ansible.builtin.systemd_service:
      #     name: jboss-eap-rhel
      #     enabled: true

      # environment, for the block
      environment:
        - "{{ shell_env }}"   #variables PATH, JBOSS_HOME, HOST_CONFIG, JBOSS_OPTION
      become: true          

    #---------------------------------------------      
    - block:  #CLI config in 'master' for 'master'

      # Template arquivo de properties para jboss-cli.sh
      - name: template 'cli-CONFIG-master-j2.properties' to 'cli-CONFIG-master.properties' in 'master'
        when: inventory_hostname in groups["master"]
        ansible.builtin.template:
          src: ./template/{{ item.src }}
          dest: "{{ config_scripts_dir }}/cli-config-master/{{ item.dest }}"
          mode: 0775
        with_items:
          - {src: 'cli-CONFIG-master-j2.properties', dest: 'cli-CONFIG-master.properties'}

      - name: execute CLI CONFIG script in 'master' for 'master'
        ansible.builtin.shell:
        when: inventory_hostname in groups["master"]
        args:
          chdir: "{{ config_scripts_dir }}/cli-config-master/"
          cmd: ./jboss-cli-master-config.sh
        register: cli
        ignore_errors: true  # in order to continue processing
        no_log: true

      # - name: Show result of previous task with line breaks
      #   when: 
      #     - inventory_hostname in groups["master"]         
      #   ansible.builtin.debug:
      #     var: "cli.stdout_lines"

      - name: Fail in case of error
        when: 
          - inventory_hostname in groups["master"]         
          - cli.failed
        ansible.builtin.fail:
          msg: 'Script failure'
        no_log: true
                   
      rescue:  #config & start
      - name: Show result with line breaks
        ansible.builtin.debug:
          #var: results.stdout_lines
          var: "{{ item }}"
        loop: "{{ cli.results }}"          

      - name: Abort execution
        when: { ansible_failed_result.failed }
        ansible.builtin.fail:
          msg: "{{ ansible_failed_result }}"

      always: #delete file cli-CONFIG-master.properties, contains sentitive data
      - name: Delete file cli-CONFIG-master.properties
        ansible.builtin.file:
          path: "{{ config_scripts_dir }}/cli-config-master/cli-CONFIG-master.properties"
          state: absent

      # end of block, for all tasks
      environment:
        - "{{ shell_env }}"
      become: true
      become_user: "{{ jboss_os_user }}"

    #---------------------------------------------      
    - block:  #CLI config in 'master' for 'slaves'

      - name: execute CLI CONFIG script in 'master' for 'slaves'
        ansible.builtin.shell:
        when: inventory_hostname in groups["master"]
        args:
          chdir: "{{ config_scripts_dir }}/cli-config-slaves/"
          cmd: ./jboss-slave-cli-config.sh {{ item }} {{ JBOSS_SERVER_GROUP }} {{ JBOSS_SERVER_CONFIG }} {{ pg_db_data_source }}
        loop: "{{ groups['slaves'] }}"
        register: cli
        ignore_errors: true  # in order to continue processing
        no_log: true

      # - name: Show result of previous task with line breaks
      #   when: 
      #     - inventory_hostname in groups["master"]         
      #   ansible.builtin.debug:
      #     var: "{{ item }}"
      #   loop: "{{ cli.results }}"

      - name: Fail in case of error
        when: 
          - inventory_hostname in groups["master"]         
          - item.failed
        ansible.builtin.fail:
          msg: '{{ item }}'
        loop: "{{ cli.results }}"  
        no_log: true
                   
      rescue:  #config & start
      - name: Show result with line breaks
        ansible.builtin.debug:
          var: "{{ item }}"
        loop: "{{ cli.results }}"
        #  var: results.stdout_lines

      - name: Abort execution
        when: { ansible_failed_result.failed }
        ansible.builtin.fail:
          msg: "{{ ansible_failed_result.msg }}"

      # end of block, for all tasks
      environment:
        - "{{ shell_env }}"
      become: true
      become_user: "{{ jboss_os_user }}"      